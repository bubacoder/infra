# LiteLLM supports all the text / chat / vision models from OpenRouter
# https://docs.litellm.ai/docs/providers/openrouter
# https://openrouter.ai/models
#
# LiteLLM supports all Anthropic models
# https://docs.litellm.ai/docs/providers/anthropic
# https://docs.anthropic.com/en/docs/about-claude/models
#
# LiteLLM supports all models from Ollama
# https://docs.litellm.ai/docs/providers/ollama
# https://github.com/ollama/ollama

---
model_list:

  # --- Via Anthropic
  #  LiteLLM provider: https://docs.litellm.ai/docs/providers/anthropic
  #  Models: https://docs.anthropic.com/en/docs/about-claude/models/overview
  #  Create API key: https://console.anthropic.com/settings/keys
  #  Buy credits: https://console.anthropic.com/settings/billing

  - model_name: claude-3-7-sonnet                # RECEIVED MODEL NAME
    litellm_params:                              # All params accepted by litellm.completion() - https://docs.litellm.ai/docs/completion/input
      model: anthropic/claude-3-7-sonnet-latest  # MODEL NAME sent to `litellm.completion()`
      api_key: "os.environ/ANTHROPIC_API_KEY"    # Does os.getenv("ANTHROPIC_API_KEY")

  - model_name: claude-opus-4-0
    litellm_params:
      model: anthropic/claude-opus-4-0
      api_key: "os.environ/ANTHROPIC_API_KEY"

  - model_name: claude-sonnet-4-0
    litellm_params:
      model: anthropic/claude-sonnet-4-0
      api_key: "os.environ/ANTHROPIC_API_KEY"

  # --- Via OpenAI
  #  LiteLLM provider: https://docs.litellm.ai/docs/providers/openai
  #  Models: https://platform.openai.com/docs/models
  #  Create API key: https://platform.openai.com/api-keys
  #  Buy credits: https://platform.openai.com/settings/organization/billing/overview

  - model_name: gpt-5
    litellm_params:
      model: openai/gpt-5
      api_key: "os.environ/OPENAI_API_KEY"

  - model_name: gpt-5-mini
    litellm_params:
      model: openai/gpt-5-mini
      api_key: "os.environ/OPENAI_API_KEY"

  # --- Via Google
  #  LiteLLM provider: https://docs.litellm.ai/docs/providers/gemini
  #  Models: https://ai.google.dev/gemini-api/docs/models
  #  Create API key: https://aistudio.google.com/apikey
  #  Buy credits: https://aistudio.google.com/apikey -> "Set up billing"

  - model_name: gemini-2.5-pro
    litellm_params:
      model: gemini/gemini-2.5-pro
      api_key: "os.environ/GEMINI_API_KEY"

  - model_name: gemini-2.5-flash
    litellm_params:
      model: gemini/gemini-2.5-flash
      api_key: "os.environ/GEMINI_API_KEY"

  # --- Via Openrouter
  #  LiteLLM provider: https://docs.litellm.ai/docs/providers/openrouter
  #  Models: https://openrouter.ai/models
  #  Create API Key: https://openrouter.ai/settings/keys
  #  Buy credits: https://openrouter.ai/settings/credits

  # https://openrouter.ai/openai/openai/gpt-4o
  - model_name: gpt-4o
    litellm_params:
      model: openrouter/openai/gpt-4o
      api_key: "os.environ/OPENROUTER_API_KEY"

  # https://openrouter.ai/openai/gpt-4o-mini
  - model_name: gpt-4o-mini
    litellm_params:
      model: openrouter/openai/gpt-4o-mini
      api_key: "os.environ/OPENROUTER_API_KEY"

  # https://openrouter.ai/openai/o4-mini-high
  - model_name: o4-mini-high
    litellm_params:
      model: openrouter/openai/o4-mini-high
      api_key: "os.environ/OPENROUTER_API_KEY"

  # https://openrouter.ai/meta-llama/llama-3.3-70b-instruct
  - model_name: llama-3.3-70b-instruct
    litellm_params:
      model: openrouter/meta-llama/llama-3.3-70b-instruct
      api_key: "os.environ/OPENROUTER_API_KEY"

  # https://openrouter.ai/deepseek/deepseek-r1-distill-llama-70b
  - model_name: deepseek-r1-distill-llama-70b
    litellm_params:
      model: openrouter/deepseek/deepseek-r1-distill-llama-70b
      api_key: "os.environ/OPENROUTER_API_KEY"

  # https://openrouter.ai/deepseek/deepseek-r1
  - model_name: deepseek-r1
    litellm_params:
      model: openrouter/deepseek/deepseek-r1
      api_key: "os.environ/OPENROUTER_API_KEY"

  # --- Local models (Ollama)
  #  LiteLLM provider: https://docs.litellm.ai/docs/providers/ollama#using-ollama-apichat
  #  Models: https://ollama.com/search

  # Local model - Phi 3.5
  - model_name: ollama-local-phi
    litellm_params:
      model: ollama_chat/phi3.5:3.8b
      api_base: "os.environ/LOCAL_OLLAMA_API_BASE"
      api_key: "none"

  # Local model - Mistral 7b
  - model_name: ollama-mac-mistral
    litellm_params:
      model: ollama_chat/mistral:7b-instruct
      api_base: "os.environ/REMOTE_OLLAMA_API_BASE"
      api_key: "none"

router_settings:
  fallbacks:
    - gpt-5:
        - gpt-4o
    - gpt-5-mini:
        - gpt-4o-mini
    - ollama-mac-mistral:
        - ollama-local-phi
